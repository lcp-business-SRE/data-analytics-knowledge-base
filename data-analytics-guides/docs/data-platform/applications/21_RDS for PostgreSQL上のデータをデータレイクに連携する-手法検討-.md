---
sidebar_position: 2
title : RDS for PostgreSQL上のデータをデータレイクに連携する-手法検討-
authors : [akiba]
tags: [データ分析,データ基盤,AWS,RDS,PostgreSQL,Iceberg,S3Tables]
---
**検討時期**: 2025年12月

## 背景

現在運用しているサービスは主にデータをDynamoDBとRDS for PostgreSQLに分けて保存していた。
2025年度の運用で、DynamoDBのデータのIcebergテーブルへの連携は完了していたが、RDS for PostgreSQL上のデータについてはまだ連携ができていなかった。
そこに2026年度は検索の必要となる要件が増えたため、2025年度まではDynamoDB上にあったデータもRDS for PostgreSQLに移行することになった。
そのため、RDS for PostgreSQL上のデータをデータレイクに連携する必要が生まれた。

## やったこと

RDS for PostgreSQL上のデータを連携する先をIcebergテーブル以外も含めて検討した。

## 要件

RDS for PostgreSQL(以下RDS)上のデータをデータレイクに連携するにあたり、以下の要件を満たすことを目標に手法の選定を開始した。

1. 本番環境のRDSインスタンスにかかる負荷を減らすこと
2. 同じデータベース上に、個人情報などの機微データが存在するため、連携するデータを制御できること
3. データレイクはサービスを運用しているAWSアカウントとは別のAWSアカウントに構築すること
4. 運用の際にサービスの設計運用を行うチームとデータ基盤の運用チームの間での調整コストが低いこと
5. データの更新は1日1回程度とする
6. コストはなるべく抑えること
7. 特定のサービスに過度に依存したり、密結合なアーキテクチャにならないこと
8. フルマネージドサービスをなるべく採用すること
9. 実現性と継続性が高いこと

### 1.〜9.の要件の背景

1. **本番環境のRDSインスタンスにかかる負荷を減らすこと**
現在運用しているインスタンスはフルスキャンや大規模なクエリを走らせる想定になっていない。そのため直接RDSに接続してデータを抽出するといった手法は採用できない
2. **同じデータベース上に、個人情報などの機微データが存在するため、連携するデータを制御できること**
運用中のRDS上には個人情報などの機微データが存在する。また、運用上リストとしてこういった情報を取得する必要があるため、これらをCognitoといったほかのサービスに移行することは難しい。しかし、データレイクにこれら個人情報を保持することは管理コストの増加やセキュリティリスクの増加を招く。よって、安全なデータのみを連携できるよう制御する必要がある
3. **データレイクはサービスを運用しているAWSアカウントとは別のAWSアカウントに構築すること**
サービスを運用しているAWSアカウントとは別にデータ基盤用のAWSアカウントがあり、そこにデータを集約するほうがセキュリティ的に望ましいため
4. **運用の際にサービスの設計運用を行うチームとデータ基盤の運用チームの間での調整コストが低いこと**
サービスを運用しているチームとデータ基盤を運用しているチームは別である。現状は直接話せる環境であり、そこまで大きな調整コストは発生していなかった。しかし、今後の運用を想定したときにCI/CD[^1]のパイプラインの変更などサービス側の大きな変更で、場合によってはデータ分析チームがサービス側のコードを変更する必要も想定される。こういった事態を避けるため、疎結合を保てるようなアーキテクチャが望ましい
5. **データの更新は1日1回程度とする**
データの更新頻度は高くないため、リアルタイム性は求められずCDC[^6]のような手法も不要
6. **コストはなるべく抑えること**
データレイクに連携するデータ量はGBスケールと多くはないことに加え予算の制約もあるため、コストはなるべく抑えたい
7. **特定のサービスに過度に依存したり、密結合なアーキテクチャにならないこと**
将来的に他のクラウドサービスなどに移行することも可能なように、AWSのサービスに過度に依存しないことが望ましい。また、部分的な変更を容易にするためにも疎結合なアーキテクチャが望ましい
8. **フルマネージドサービスをなるべく採用すること**
データ分析チームのリソースが極めて小さいことと、本質的な価値を生み出す業務に集中したい。そのため、運用コストの低いフルマネージドサービスを中心に検討した
9. **実現性と継続性が高いこと**
実現のための工数が膨大になったり、技術的難易度が高い手法は避けたい。また将来的なメンテナンスやサポートが期待できること

## データレイクの検討

RDS上のデータをデータレイクに連携する手法として、まずはデータを集積する場所を検討した。

### DWH(データウェアハウス)

Amazon RedshiftやSnowflake、Google BigQueryなどのDWH[^2]。
DWHは大量のデータを高速に分析することに特化したサービスであり、本来データレイクを別途用意することが多い。しかし、DWH自体に管理しやすい形でデータを保管できるため、データレイクの代替として利用することも可能。

### 旧来のデータレイク

RDS上のデータをS3に保存することができるので、それをデータレイクとして利用し、Athenaで直接クエリを実行する手法。

### データレイクハウス

IcebergやDelta Lake、Apache Hudiなどのテーブルフォーマットを利用してS3上にデータレイクを構築し、AthenaやEMR、Databricksなどでクエリを実行する手法。

### 検討結果

以下の表のように整理した結果、以下の3つの構成が有力候補として残った。

- データレイクハウス利用構成
  - S3Tables + Athena
  - S3 + Iceberg + GlueCatalog + Athena
- DWH利用構成
  - Google BigQuery

|大分類|具体的サービス|強み|弱み|所感|
|-|--|--|--|--|
|DWH|全般|データ分析に特化した機能が豊富|高価な場合が多い|高コストな分高性能だが、現状はそこまで必要ではない|
||Amazon Redshift|AWSのフルマネージドサービスであり、連携手段が豊富|費用が高価<br />AWSのエコシステムありき<br />ベンダーロックインの危険|インスタンス課金制なので、コスト面から除外|
||Snowflake|代表的DWHで、高機能<br />様々なクラウドプロバイダから選択して運用可能|高価|費用面と目的から、今すぐ使用する必要性は薄い|
||Google BigQuery|比較的低コストな従量課金制<br />メジャーな選択肢|マルチクラウド構成になる|検証用環境を用意できていないため、それを用意してから後日試す候補|
|旧来のデータレイク|S3 + Athena|構成がシンプル<br />RDS・DynamoDBともに、S3上にデータをマネージドな機能でエクスポート可能|拡張していくにしたがって、データの運用が難しくなる<br />データ分析の基盤として設計されているわけではない|下のレイクハウスに勝てないので除外|
|データレイクハウス|全般|データ基盤の要件を満たすように設計されている<br />疎結合が実現できる<br />将来的にDWHへの接続も視野に入る|複雑<br />性能を生かすには自分で管理する必要がある||
||S3 + GlueCatalog + Iceberg + Athena|2025年度にDynamoDBのデータで実行済み|管理が手動|有力候補として検討中|
||S3Tables + Athena|マネージドなIcebergテーブル|一部のAWSのマネージドサービスとの接続が難しい|有力候補として検討中|

### データレイク検討結果まとめ

先ほど挙げた3つの構成について、連携手法も加えて詳細に検討を進めた。

|構成|連携手法|管理|環境準備|備考|
|:--:|:--:|:--|:--|:--|
|S3Tables|1. Glue Job経由<br />2. DMS[^3]経由|設定は最小限|既存のPoC[^5]用AWSアカウントが利用可能|運用経験はないが、AWSでの経験は効く|
|セルフマネージドな、S3上のIcebergテーブル|1. Glue Job経由<br />2. DMS[^3]経由<br />3. Firehose経由|コンパクション[^4]など設定が必要|既存のPoC[^5]用AWSアカウントが利用可能|2025年度に既に、ある程度運用している|
|BigQuery|1. Data Transfer Service|DWH的な機能が豊富で管理も容易|新規GCPアカウントが必要|GCPの経験値がほぼない|

結果、以下の理由からAWSのS3上でIcebergテーブルを利用するデータレイクハウス構成のどちらかを採用することにした。
また連携が可能な場合は、検証を兼ねるためにS3Tablesを優先的に利用することにした。

**共通の理由**:

- 検証環境をすぐに用意できる
  - BigQueryは検証環境を用意できていなかった
- 連携手段が複数あり、方針変更がしやすい
  - Glue Job経由、DMS[^3]経由、Firehose経由と複数の手法が検討できる

**S3Tablesの利用を優先する理由**:

- S3Tablesを試していないため、検証を兼ねられる
  - S3+Iceberg+GlueCatalog+Athena構成は2025年度にDynamoDBのデータで実証済み

## 連携方法の検討

RDSのスナップショットデータをS3上のIcebergテーブルに連携する手法として、以下の3つの手法を検討した。

- Firehose経由で連携
- DMS[^3]経由で連携
- Glue Job経由で連携

### Firehose経由で連携

本命として検討した手法。

#### 内容

[FirehoseによるRDSのCDCの更新をIcebergテーブルへ配信する機能](https://aws.amazon.com/jp/blogs/news/replicate-changes-from-databases-to-apache-iceberg-tables-using-amazon-data-firehose/)を利用し、更新を逐次データレイクに反映する。
この方式を使う場合はセルフマネージドのテーブルを使用する必要がある。

#### 強み

- リアルタイム性が高い
- 運用コストが低い
- 構築が容易
- RDSインスタンスへの負荷が低い
- 連携するデータを柔軟に制御できる
  - Filter機能が利用できる

#### 弱み

- CDCキャプチャのために、RDSインスタンスの設定変更が必要
  - 変更自体は軽微
- RDSインスタンスのバージョンが対応していないと利用できない
  - 現在のRDSインスタンスで対応可能
- S3Tablesには連携できない
- プレビュー版であり、一般提供ではない
- **提供が2025年の10月でいったん終了していた**

### DMS経由で連携

#### 内容

DMS[^3]のIcebergターゲットエンドポイントを利用して、RDSのCDC[^6]をS3TablesもしくはセルフマネージドなIcebergテーブルに連携する。

#### 強み

- リアルタイム性が高い
- 文献が多い
- データの連携に特化したサービスである
- フィルタ機能があり、連携するデータを柔軟に制御できる

#### 弱み

- RDSインスタンスの負荷が高い
- サービスのコストが高い
- RDSを保持しているアカウントでDMSを構築するのが自然な構成
  - サービス間の結合度が高くなる

### Glue Job経由で連携

#### 内容

RDSのスナップショットをS3にエクスポートし、Glue JobでS3TablesもしくはセルフマネージドなIcebergテーブルに連携する。

#### 強み

- RDSインスタンスへの負荷が低い
  - スナップショットの取得はすでに運用しており、新規に与える負荷はない
- 連携するデータを柔軟に制御できる
  - スナップショットのエクスポート時に、ホワイトリスト方式[^7]でのテーブル選択が可能
- 切り替えが容易
  - 将来的にDMS[^3]やFirehoseに切り替えることも可能

#### 弱み

- リアルタイム性が低い
  - スナップショットの取得頻度が1日1回程度のため
- 運用コストが高い
  - Glue Jobのメンテナンスが必要
  - Jobの実行にもコストがかかり、規模が大きくなるとDMS[^3]よりも高価になる
- 構築がやや複雑
  - Glue Jobの実装が必要
  - 権限設定もやや複雑

### 連携方式検討結果まとめ

以下の理由から**Glue Job経由でRDSのスナップショットデータをS3Tablesに連携する**手法を試すことにした。

- **スナップショットとGlue Job経由**
  - 以下のメリットを重視した
    - RDSインスタンスへの負荷が低い
    - 連携するデータを柔軟に制御できる
    - データソース側での設定が必要最小限
  - 以下のデメリットは許容
    - リアルタイム性が低い
      - 今回の要件では不要
    - 変換コードのメンテナンスが必要
      - 構造化データのみならばコードは汎用的にできる
    - 構築がやや複雑
      - IaC[^8]化を検討
    - 大規模になるとコストが跳ね上がる
      - 現状の規模ならこちらの方が経済的
    - 処理が大規模になったらDMS[^3]や(GA[^9]された場合は)Firehoseへの乗り換える必要性がある
- **Firehose経由**
  - 最有力候補もプレビュー提供が終わっていたため候補から除外
- **DMS経由**
  - 以下のデメリットが重く不採用
    - RDSインスタンスへの負荷が高い
    - 小規模な転送だとコストが高い
    - AWSのマネージドサービスへの依存性に対する懸念
  - 以下のメリットは魅力的だった
    - リアルタイム性が高い
    - データ転送に特化

## 選定結果

以上の結果、今回検証する構成は以下のようになる。

### 検証構成

今回はPoC[^5]用アカウント上にRDSインスタンスを立ち上げて1アカウント構成で検証を実施した。

#### 今回の検証構成

![構成図](../assets/構成図-POC.svg)

#### 実運用の予定構成

![構成図](../assets/prod-構成図.svg)

別途スナップショットのクロスアカウント共有が可能なことは確認している。

### 連携処理フロー

今回実装した処理のフローを以下に示す。

```mermaid
sequenceDiagram
    
    actor User as 操作者
    participant KMS

    box transparent 実運用時ソース側アカウントにあることを想定
    participant RDS as データソースDB(RDS)
    participant snapshot as RDSスナップショット
    end
    User->>RDS: スナップショット作成操作
    RDS->>KMS: KMSキー取得
    RDS->>snapshot: スナップショット作成
    destroy snapshot
    participant S3 as スナップショット保存先S3バケット
    snapshot->>S3: スナップショットエクスポート

    create participant GlueJob as Glue Job
    User->>+GlueJob: ジョブ実行
    note over GlueJob: 詳細は別ページ参照
    participant S3Tables as データレイク
    GlueJob->>KMS: KMSキー取得
    GlueJob->>S3: スナップショットデータ読込
    GlueJob->>S3Tables: データ連携処理
    deactivate GlueJob
    destroy GlueJob
    GlueJob-->>User: ジョブ完了通知
    Athena->>S3Tables: データクエリ実行
```

[^1]: CI/CD (Continuous Integration/Continuous Delivery): 継続的インテグレーション/継続的デリバリー。コードの変更を自動的にビルド、テスト、デプロイするための開発手法

[^2]: DWH (Data Warehouse): データウェアハウス。大量のデータを集約して分析するためのデータベースシステム

[^3]: DMS (Database Migration Service): データベース移行サービス。データベース間のデータ移行やレプリケーションを行うAWSのサービス

[^4]: コンパクション (Compaction): Icebergテーブルの最適化処理。小さなファイルを統合して読み取り性能を向上させる

[^5]: PoC (Proof of Concept): 概念実証。新しい技術やアイデアの実現可能性を検証すること

[^6]: CDC (Change Data Capture): 変更データキャプチャ。データベースの変更をリアルタイムで検出・取得する技術

[^7]: ホワイトリスト方式: 指定したもののみを許可する方式

[^8]: IaC (Infrastructure as Code): コードとしてのインフラ。インフラ構成をコードで管理する手法

[^9]: GA (General Availability): 一般提供。AWSのサービスが正式に提供されること
